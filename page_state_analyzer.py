"""
é¡µé¢çŠ¶æ€åˆ†æå™¨
ç”¨äºè¯†åˆ«å½“å‰é«˜å¾·åœ°å›¾é¡µé¢çš„çŠ¶æ€ç±»å‹ï¼Œåˆ¤æ–­æ˜¯å¦åŒ…å«å•†å®¶å¡ç‰‡åˆ—è¡¨

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è¯†åˆ«é¡µé¢ç±»å‹ï¼ˆæœç´¢ç»“æœé¡µã€å•†å®¶è¯¦æƒ…é¡µã€åœ°å›¾é¡µç­‰ï¼‰
2. éªŒè¯æ˜¯å¦æœ‰å•†å®¶å¡ç‰‡åˆ—è¡¨
3. æå–é¡µé¢å…³é”®å…ƒç´ ä¿¡æ¯
4. æ”¯æŒå¤šåŸå¸‚å¸ƒå±€å·®å¼‚
"""
import re
from typing import Dict, List, Optional
from lxml import etree


class PageStateAnalyzer:
    """é¡µé¢çŠ¶æ€åˆ†æå™¨"""

    # é¡µé¢ç±»å‹å¸¸é‡
    PAGE_TYPE_SEARCH_RESULT = "search_result"      # æœç´¢ç»“æœé¡µ
    PAGE_TYPE_MERCHANT_DETAIL = "merchant_detail"  # å•†å®¶è¯¦æƒ…é¡µ
    PAGE_TYPE_MAP_VIEW = "map_view"                # åœ°å›¾è§†å›¾
    PAGE_TYPE_UNKNOWN = "unknown"                  # æœªçŸ¥é¡µé¢

    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # æœç´¢ç»“æœé¡µç‰¹å¾å…³é”®è¯
        self.search_result_keywords = [
            'RecyclerView',  # åˆ—è¡¨å®¹å™¨
            'æœç´¢', 'é™„è¿‘', 'ç­›é€‰',
            'é«˜å¾·ç”„é€‰', 'é«˜å¾·æ¨è'
        ]

        # å•†å®¶è¯¦æƒ…é¡µç‰¹å¾å…³é”®è¯
        self.detail_page_keywords = [
            'æ‹¨æ‰“ç”µè¯', 'åˆ°è¿™å»', 'æ”¶è—', 'åˆ†äº«',
            'åœ°å€', 'è¥ä¸šæ—¶é—´', 'ç®€ä»‹'
        ]

        # å•†å®¶å¡ç‰‡ç‰¹å¾
        self.merchant_card_patterns = [
            r'èŠ±åº—|èŠ±å‰|é²œèŠ±|èŠ±è‰º',  # å•†å®¶åç§°æ¨¡å¼
            r'å››å·çœ|æˆéƒ½|æ˜†æ˜',      # åœ°å€æ¨¡å¼
            r'\d+äººå»è¿‡|\d+äººå’¨è¯¢',   # ç»Ÿè®¡ä¿¡æ¯
            r'è¥ä¸šä¸­|å·²æ‰“çƒŠ',         # è¥ä¸šçŠ¶æ€
        ]

    def analyze_page(self, xml_content: str, debug: bool = False) -> Dict:
        """
        åˆ†æé¡µé¢çŠ¶æ€

        Args:
            xml_content: UIå±‚çº§XMLå†…å®¹
            debug: æ˜¯å¦å¯ç”¨è°ƒè¯•è¾“å‡º

        Returns:
            åˆ†æç»“æœå­—å…¸ï¼š
            {
                'page_type': str,           # é¡µé¢ç±»å‹
                'has_merchant_list': bool,  # æ˜¯å¦åŒ…å«å•†å®¶åˆ—è¡¨
                'merchant_count': int,      # å•†å®¶å¡ç‰‡æ•°é‡ï¼ˆä¼°ç®—ï¼‰
                'layout_type': str,         # å¸ƒå±€ç±»å‹ï¼ˆfull_width/narrowï¼‰
                'confidence': float,        # ç½®ä¿¡åº¦
                'features': List[str]       # è¯†åˆ«åˆ°çš„ç‰¹å¾
            }
        """
        if not xml_content:
            return self._empty_result("XMLå†…å®¹ä¸ºç©º")

        try:
            root = etree.fromstring(xml_content.encode('utf-8'))

            # ç¬¬1æ­¥ï¼šè¯†åˆ«é¡µé¢ç±»å‹
            page_type = self._identify_page_type(root)

            # ç¬¬2æ­¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å•†å®¶åˆ—è¡¨
            has_merchant_list = self._has_merchant_list(root)

            # ç¬¬3æ­¥ï¼šä¼°ç®—å•†å®¶å¡ç‰‡æ•°é‡
            merchant_count = self._estimate_merchant_count(root)

            # ç¬¬4æ­¥ï¼šè¯†åˆ«å¸ƒå±€ç±»å‹
            layout_type = self._identify_layout_type(root)

            # ç¬¬5æ­¥ï¼šæå–é¡µé¢ç‰¹å¾
            features = self._extract_features(root)

            # ç¬¬6æ­¥ï¼šè®¡ç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(
                page_type, has_merchant_list, merchant_count, features
            )

            result = {
                'page_type': page_type,
                'has_merchant_list': has_merchant_list,
                'merchant_count': merchant_count,
                'layout_type': layout_type,
                'confidence': confidence,
                'features': features
            }

            if debug:
                self._print_analysis_result(result)

            return result

        except Exception as e:
            if debug:
                print(f"âœ— é¡µé¢åˆ†æå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            return self._empty_result(f"åˆ†æå¼‚å¸¸: {e}")

    def _identify_page_type(self, root) -> str:
        """è¯†åˆ«é¡µé¢ç±»å‹"""
        # æŸ¥æ‰¾RecyclerViewï¼ˆæœç´¢ç»“æœé¡µçš„åˆ—è¡¨å®¹å™¨ï¼‰
        recyclerviews = root.xpath('//node[@class="androidx.recyclerview.widget.RecyclerView"]')
        if recyclerviews:
            return self.PAGE_TYPE_SEARCH_RESULT

        # æŸ¥æ‰¾å•†å®¶è¯¦æƒ…é¡µç‰¹å¾
        all_text = self._get_all_text(root)
        detail_keywords_found = sum(1 for kw in self.detail_page_keywords if kw in all_text)
        if detail_keywords_found >= 3:
            return self.PAGE_TYPE_MERCHANT_DETAIL

        # å…¶ä»–æƒ…å†µ
        return self.PAGE_TYPE_UNKNOWN

    def _has_merchant_list(self, root) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å•†å®¶åˆ—è¡¨"""
        # ç­–ç•¥1ï¼šæŸ¥æ‰¾RecyclerView
        recyclerviews = root.xpath('//node[@class="androidx.recyclerview.widget.RecyclerView"]')
        if not recyclerviews:
            return False

        # ç­–ç•¥2ï¼šæŸ¥æ‰¾ViewGroupåˆ—è¡¨é¡¹ï¼ˆè‡³å°‘3ä¸ªæ‰ç®—åˆ—è¡¨ï¼‰
        for recyclerview in recyclerviews:
            viewgroups = recyclerview.xpath(
                './/node[@class="android.view.ViewGroup" and @clickable="true"]'
            )
            if len(viewgroups) >= 3:
                return True

        return False

    def _estimate_merchant_count(self, root) -> int:
        """ä¼°ç®—å•†å®¶å¡ç‰‡æ•°é‡"""
        recyclerviews = root.xpath('//node[@class="androidx.recyclerview.widget.RecyclerView"]')
        if not recyclerviews:
            return 0

        max_count = 0
        for recyclerview in recyclerviews:
            # æŸ¥æ‰¾å¯ç‚¹å‡»çš„ViewGroup
            viewgroups = recyclerview.xpath(
                './/node[@class="android.view.ViewGroup" and @clickable="true" and @bounds]'
            )

            # è¿‡æ»¤ï¼šåªç»Ÿè®¡é«˜åº¦åœ¨100-500èŒƒå›´å†…çš„èŠ‚ç‚¹
            valid_cards = []
            for vg in viewgroups:
                bounds_str = vg.get('bounds', '')
                match = re.match(r'\[(\d+),(\d+)\]\[(\d+),(\d+)\]', bounds_str)
                if match:
                    x1, y1, x2, y2 = map(int, match.groups())
                    height = y2 - y1
                    if 100 <= height <= 500:
                        valid_cards.append(vg)

            max_count = max(max_count, len(valid_cards))

        return max_count

    def _identify_layout_type(self, root) -> str:
        """
        è¯†åˆ«å¸ƒå±€ç±»å‹

        Returns:
            'full_width': å…¨å±å®½åº¦å¸ƒå±€ï¼ˆæ˜†æ˜ç­‰ï¼‰
            'narrow': çª„ç‰ˆå¸ƒå±€ï¼ˆæˆéƒ½ç­‰ï¼‰
            'unknown': æœªçŸ¥å¸ƒå±€
        """
        recyclerviews = root.xpath('//node[@class="androidx.recyclerview.widget.RecyclerView"]')
        if not recyclerviews:
            return 'unknown'

        # é‡‡æ ·æ£€æŸ¥å‰3ä¸ªViewGroupçš„å®½åº¦
        for recyclerview in recyclerviews:
            viewgroups = recyclerview.xpath(
                './/node[@class="android.view.ViewGroup" and @clickable="true" and @bounds]'
            )[:3]

            for vg in viewgroups:
                bounds_str = vg.get('bounds', '')
                match = re.match(r'\[(\d+),(\d+)\]\[(\d+),(\d+)\]', bounds_str)
                if match:
                    x1, y1, x2, y2 = map(int, match.groups())
                    width = x2 - x1

                    # å‡è®¾å±å¹•å®½åº¦1080
                    width_ratio = width / 1080
                    if width_ratio >= 0.85:
                        return 'full_width'
                    elif 0.60 <= width_ratio < 0.75:
                        return 'narrow'

        return 'unknown'

    def _extract_features(self, root) -> List[str]:
        """æå–é¡µé¢ç‰¹å¾"""
        features = []
        all_text = self._get_all_text(root)

        # æ£€æŸ¥RecyclerView
        if root.xpath('//node[@class="androidx.recyclerview.widget.RecyclerView"]'):
            features.append('has_recyclerview')

        # æ£€æŸ¥å•†å®¶åç§°æ¨¡å¼
        for pattern in self.merchant_card_patterns:
            if re.search(pattern, all_text):
                features.append(f'pattern:{pattern[:10]}')

        # æ£€æŸ¥æ˜¯å¦æœ‰è¯„åˆ†ä¿¡æ¯
        if re.search(r'\d\.\d\s*åˆ†|å¾ˆå¥½|è¶…æ£’', all_text):
            features.append('has_rating')

        # æ£€æŸ¥æ˜¯å¦æœ‰è·ç¦»ä¿¡æ¯
        if re.search(r'\d+\.?\d*\s?(å…¬é‡Œ|km|ç±³|m)', all_text):
            features.append('has_distance')

        # æ£€æŸ¥æ˜¯å¦æœ‰è¥ä¸šçŠ¶æ€
        if re.search(r'è¥ä¸šä¸­|å·²æ‰“çƒŠ|æš‚åœè¥ä¸š', all_text):
            features.append('has_business_status')

        return features

    def _calculate_confidence(
        self, page_type: str, has_merchant_list: bool,
        merchant_count: int, features: List[str]
    ) -> float:
        """è®¡ç®—é¡µé¢è¯†åˆ«ç½®ä¿¡åº¦"""
        confidence = 0.0

        # å› ç´ 1ï¼šé¡µé¢ç±»å‹ï¼ˆ40åˆ†ï¼‰
        if page_type == self.PAGE_TYPE_SEARCH_RESULT:
            confidence += 0.4
        elif page_type == self.PAGE_TYPE_MERCHANT_DETAIL:
            confidence += 0.2
        else:
            confidence += 0.1

        # å› ç´ 2ï¼šå•†å®¶åˆ—è¡¨å­˜åœ¨æ€§ï¼ˆ30åˆ†ï¼‰
        if has_merchant_list:
            confidence += 0.3

        # å› ç´ 3ï¼šå•†å®¶æ•°é‡ï¼ˆ20åˆ†ï¼‰
        if merchant_count >= 3:
            confidence += 0.2
        elif merchant_count >= 1:
            confidence += 0.1

        # å› ç´ 4ï¼šç‰¹å¾æ•°é‡ï¼ˆ10åˆ†ï¼‰
        feature_score = min(len(features) * 0.02, 0.1)
        confidence += feature_score

        return min(confidence, 1.0)

    def _get_all_text(self, root) -> str:
        """è·å–é¡µé¢æ‰€æœ‰æ–‡æœ¬å†…å®¹"""
        texts = []

        # ä»content-descè·å–
        for node in root.xpath('//node[@content-desc]'):
            desc = node.get('content-desc', '').strip()
            if desc:
                texts.append(desc)

        # ä»textå±æ€§è·å–
        for node in root.xpath('//node[@text]'):
            text = node.get('text', '').strip()
            if text:
                texts.append(text)

        return ' '.join(texts)

    def _empty_result(self, reason: str) -> Dict:
        """è¿”å›ç©ºç»“æœ"""
        return {
            'page_type': self.PAGE_TYPE_UNKNOWN,
            'has_merchant_list': False,
            'merchant_count': 0,
            'layout_type': 'unknown',
            'confidence': 0.0,
            'features': [],
            'error': reason
        }

    def _print_analysis_result(self, result: Dict):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*80)
        print("ğŸ“Š é¡µé¢çŠ¶æ€åˆ†æç»“æœ")
        print("="*80)
        print(f"é¡µé¢ç±»å‹: {result['page_type']}")
        print(f"åŒ…å«å•†å®¶åˆ—è¡¨: {'âœ“ æ˜¯' if result['has_merchant_list'] else 'âœ— å¦'}")
        print(f"å•†å®¶å¡ç‰‡æ•°é‡: {result['merchant_count']}")
        print(f"å¸ƒå±€ç±»å‹: {result['layout_type']}")
        print(f"ç½®ä¿¡åº¦: {result['confidence']:.2%}")
        print(f"è¯†åˆ«ç‰¹å¾: {', '.join(result['features']) if result['features'] else 'æ— '}")
        if 'error' in result:
            print(f"âš  é”™è¯¯: {result['error']}")
        print("="*80 + "\n")

    def verify_merchant_detail_page(self, xml_content: str, expected_name: str = None) -> Dict:
        """
        éªŒè¯æ˜¯å¦è¿›å…¥äº†æ­£ç¡®çš„å•†å®¶è¯¦æƒ…é¡µ

        Args:
            xml_content: UIå±‚çº§XMLå†…å®¹
            expected_name: æœŸæœ›çš„å•†å®¶åç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            éªŒè¯ç»“æœå­—å…¸ï¼š
            {
                'is_detail_page': bool,      # æ˜¯å¦æ˜¯è¯¦æƒ…é¡µ
                'merchant_name': str,        # æå–åˆ°çš„å•†å®¶å
                'has_phone': bool,           # æ˜¯å¦æœ‰ç”µè¯å·ç 
                'has_address': bool,         # æ˜¯å¦æœ‰åœ°å€
                'match_expected': bool,      # æ˜¯å¦åŒ¹é…æœŸæœ›çš„å•†å®¶å
                'confidence': float          # éªŒè¯ç½®ä¿¡åº¦
            }
        """
        if not xml_content:
            return {
                'is_detail_page': False,
                'merchant_name': '',
                'has_phone': False,
                'has_address': False,
                'match_expected': False,
                'confidence': 0.0
            }

        try:
            root = etree.fromstring(xml_content.encode('utf-8'))
            all_text = self._get_all_text(root)

            # æ£€æŸ¥è¯¦æƒ…é¡µç‰¹å¾
            is_detail_page = self._identify_page_type(root) == self.PAGE_TYPE_MERCHANT_DETAIL

            # æå–å•†å®¶åï¼ˆé€šå¸¸åœ¨é¡µé¢é¡¶éƒ¨ï¼‰
            merchant_name = self._extract_merchant_name_from_detail(root)

            # æ£€æŸ¥æ˜¯å¦æœ‰ç”µè¯å·ç 
            has_phone = bool(re.search(r'1[3-9]\d{9}|æ‹¨æ‰“ç”µè¯|ç”µè¯', all_text))

            # æ£€æŸ¥æ˜¯å¦æœ‰åœ°å€
            has_address = bool(re.search(r'åœ°å€|å››å·çœ|æˆéƒ½|æ˜†æ˜|åŒº.*è·¯|è¡—é“', all_text))

            # æ£€æŸ¥æ˜¯å¦åŒ¹é…æœŸæœ›çš„å•†å®¶å
            match_expected = False
            if expected_name and merchant_name:
                # æ¨¡ç³ŠåŒ¹é…ï¼šæå–å…³é”®è¯
                expected_keywords = set(expected_name.replace(' ', ''))
                merchant_keywords = set(merchant_name.replace(' ', ''))
                common = expected_keywords & merchant_keywords
                match_expected = len(common) >= min(4, len(expected_keywords) * 0.5)

            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = 0.0
            if is_detail_page:
                confidence += 0.4
            if has_phone:
                confidence += 0.2
            if has_address:
                confidence += 0.2
            if match_expected:
                confidence += 0.2

            return {
                'is_detail_page': is_detail_page,
                'merchant_name': merchant_name,
                'has_phone': has_phone,
                'has_address': has_address,
                'match_expected': match_expected,
                'confidence': confidence
            }

        except Exception as e:
            print(f"âœ— è¯¦æƒ…é¡µéªŒè¯å¤±è´¥: {e}")
            return {
                'is_detail_page': False,
                'merchant_name': '',
                'has_phone': False,
                'has_address': False,
                'match_expected': False,
                'confidence': 0.0
            }

    def _extract_merchant_name_from_detail(self, root) -> str:
        """ä»è¯¦æƒ…é¡µæå–å•†å®¶åç§°"""
        # ç­–ç•¥1ï¼šæŸ¥æ‰¾é¡µé¢é¡¶éƒ¨çš„å¤§æ ‡é¢˜ï¼ˆé€šå¸¸Yåæ ‡ < 500ï¼‰
        nodes = root.xpath('//node[@text and @bounds]')
        candidates = []

        for node in nodes:
            text = node.get('text', '').strip()
            bounds_str = node.get('bounds', '')

            if not text or len(text) < 3:
                continue

            # è§£æåæ ‡
            match = re.match(r'\[(\d+),(\d+)\]\[(\d+),(\d+)\]', bounds_str)
            if match:
                x1, y1, x2, y2 = map(int, match.groups())

                # é¡¶éƒ¨åŒºåŸŸï¼Œè¾ƒå¤§å­—å·ï¼ˆæ¨æ–­ï¼‰
                if y1 < 500 and len(text) >= 4:
                    candidates.append((y1, text))

        # é€‰æ‹©Yåæ ‡æœ€å°çš„ï¼ˆæœ€é è¿‘é¡¶éƒ¨ï¼‰
        if candidates:
            candidates.sort(key=lambda x: x[0])
            return candidates[0][1]

        return ""
